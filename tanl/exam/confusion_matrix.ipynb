{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b272d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "confusion_matrix =np.array([[ 97,14,45,63,83],\n",
    "            [28,13,31,85,93],\n",
    "            [71,9,92,47,115],\n",
    "            [14,8,22,184,34],\n",
    "            [42,15,42,58,187]])\n",
    "\n",
    "\n",
    "true_positives = np.diag(confusion_matrix)\n",
    "false_positives = np.sum(confusion_matrix, axis=0) - true_positives\n",
    "false_negatives = np.sum(confusion_matrix, axis=1) - true_positives\n",
    "\n",
    "total_instances = confusion_matrix.sum()\n",
    "# Calculate True Negatives for each class\n",
    "true_negatives = []\n",
    "for i in range(confusion_matrix.shape[0]):\n",
    "    tn = total_instances - (confusion_matrix[i, :].sum() + confusion_matrix[:, i].sum() - confusion_matrix[i, i])\n",
    "    true_negatives.append(tn)\n",
    "\n",
    "\n",
    "precision = np.nan_to_num(np.divide(true_positives, (true_positives + false_positives)))\n",
    "recall = np.nan_to_num(np.divide(true_positives, (true_positives + false_negatives)))\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Micro calculations\n",
    "micro_precision = true_positives.sum() / (true_positives + false_positives).sum()\n",
    "micro_recall = true_positives.sum() / (true_positives + false_negatives).sum()\n",
    "micro_f1 = 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall)\n",
    "\n",
    "# Macro calculations\n",
    "macro_precision = np.mean(precision)\n",
    "macro_recall = np.mean(recall)\n",
    "macro_f1 = np.mean(f1_scores)\n",
    "\n",
    "# Weighted calculations\n",
    "weights = confusion_matrix.sum(axis=1) / total_instances\n",
    "weighted_precision = np.sum(precision * weights)\n",
    "weighted_recall = np.sum(recall * weights)\n",
    "weighted_f1 = np.sum(f1_scores * weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a66ae89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives for each class: [ 97  13  92 184 187]\n",
      "False Positives for each class: [155  46 140 253 325]\n",
      "True Negatives for each class: [1035, 1196, 1018, 977, 823]\n",
      "False Negatives for each class: [205 237 242  78 157]\n"
     ]
    }
   ],
   "source": [
    "print(\"True Positives for each class:\", true_positives)\n",
    "print(\"False Positives for each class:\", false_positives)\n",
    "print(\"True Negatives for each class:\", true_negatives)\n",
    "print(\"False Negatives for each class:\", false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de6d5691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for each class: [0.38492063 0.22033898 0.39655172 0.42105263 0.36523438]\n",
      "Recall for each class: [0.32119205 0.052      0.2754491  0.70229008 0.54360465]\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision for each class:\", precision)\n",
    "print(\"Recall for each class:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86441eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Precision: 0.38404825737265413\n",
      "Micro Recall: 0.38404825737265413\n",
      "Micro F1 Score: 0.38404825737265413\n"
     ]
    }
   ],
   "source": [
    "print(\"Micro Precision:\", micro_precision)\n",
    "print(\"Micro Recall:\", micro_recall)\n",
    "print(\"Micro F1 Score:\", micro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d36ba489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Precision: 0.3576196697376722\n",
      "Macro Recall: 0.37890717645504157\n",
      "Macro F1 Score: 0.344558701570777\n"
     ]
    }
   ],
   "source": [
    "print(\"Macro Precision:\", macro_precision)\n",
    "print(\"Macro Recall:\", macro_recall)\n",
    "print(\"Macro F1 Score:\", macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4624bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Precision: 0.361752994533845\n",
      "Weighted Recall: 0.38404825737265413\n",
      "Weighted F1 Score: 0.35094026391704214\n"
     ]
    }
   ],
   "source": [
    "print(\"Weighted Precision:\", weighted_precision)\n",
    "print(\"Weighted Recall:\", weighted_recall)\n",
    "print(\"Weighted F1 Score:\", weighted_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ac87121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision Calculation Breakdown:\n",
      "Class 1:\n",
      "  True Positives (TP): 97\n",
      "  False Positives (FP): 155\n",
      "  Precision: TP / (TP + FP) = 97 / (97 + 155) = 0.3849\n",
      "Class 2:\n",
      "  True Positives (TP): 13\n",
      "  False Positives (FP): 46\n",
      "  Precision: TP / (TP + FP) = 13 / (13 + 46) = 0.2203\n",
      "Class 3:\n",
      "  True Positives (TP): 92\n",
      "  False Positives (FP): 140\n",
      "  Precision: TP / (TP + FP) = 92 / (92 + 140) = 0.3966\n",
      "Class 4:\n",
      "  True Positives (TP): 184\n",
      "  False Positives (FP): 253\n",
      "  Precision: TP / (TP + FP) = 184 / (184 + 253) = 0.4211\n",
      "Class 5:\n",
      "  True Positives (TP): 187\n",
      "  False Positives (FP): 325\n",
      "  Precision: TP / (TP + FP) = 187 / (187 + 325) = 0.3652\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPrecision Calculation Breakdown:\")\n",
    "for i, (tp, fp) in enumerate(zip(true_positives, false_positives)):\n",
    "    class_precision = precision[i]\n",
    "    print(f\"Class {i+1}:\")\n",
    "    print(f\"  True Positives (TP): {tp}\")\n",
    "    print(f\"  False Positives (FP): {fp}\")\n",
    "    print(f\"  Precision: TP / (TP + FP) = {tp} / ({tp} + {fp}) = {class_precision:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "646295c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Micro Precision Calculation:\n",
      "  Total True Positives (TP) across all classes: 573\n",
      "  Total False Positives (FP) across all classes: 919\n",
      "  Micro Precision: Total TP / (Total TP + Total FP) = 573 / (573 + 919) = 0.3840\n",
      "\n",
      "Macro Precision Calculation:\n",
      "  Sum of Precisions for each class: 1.7880983486883608\n",
      "  Number of classes: 5\n",
      "  Macro Precision: Sum of Precisions / Number of Classes = 1.7880983486883608 / 5 = 0.3576\n",
      "\n",
      "Weighted Precision Calculation:\n",
      "  Class 1 Precision: 0.3849, Weight (Number of instances in class): 302\n",
      "  Class 2 Precision: 0.2203, Weight (Number of instances in class): 250\n",
      "  Class 3 Precision: 0.3966, Weight (Number of instances in class): 334\n",
      "  Class 4 Precision: 0.4211, Weight (Number of instances in class): 262\n",
      "  Class 5 Precision: 0.3652, Weight (Number of instances in class): 344\n",
      "  Sum of weighted precisions: 539.7354678444967\n",
      "  Total number of instances: 1492\n",
      "  Weighted Precision: Sum of Weighted Precisions / Total Instances = 539.7354678444967 / 1492 = 0.3618\n"
     ]
    }
   ],
   "source": [
    "# ... [previous precision calculation code] ...\n",
    "\n",
    "# Micro Precision calculation with explanatory print statement\n",
    "total_tp = true_positives.sum()\n",
    "total_fp = false_positives.sum()\n",
    "micro_precision_computed = total_tp / (total_tp + total_fp)\n",
    "print(\"\\nMicro Precision Calculation:\")\n",
    "print(f\"  Total True Positives (TP) across all classes: {total_tp}\")\n",
    "print(f\"  Total False Positives (FP) across all classes: {total_fp}\")\n",
    "print(f\"  Micro Precision: Total TP / (Total TP + Total FP) = {total_tp} / ({total_tp} + {total_fp}) = {micro_precision_computed:.4f}\")\n",
    "\n",
    "# Macro Precision calculation with explanatory print statement\n",
    "print(\"\\nMacro Precision Calculation:\")\n",
    "print(f\"  Sum of Precisions for each class: {np.sum(precision)}\")\n",
    "print(f\"  Number of classes: {len(precision)}\")\n",
    "print(f\"  Macro Precision: Sum of Precisions / Number of Classes = {np.sum(precision)} / {len(precision)} = {macro_precision:.4f}\")\n",
    "\n",
    "# Weighted Precision calculation with explanatory print statement\n",
    "weighted_sums = precision * confusion_matrix.sum(axis=1)\n",
    "print(\"\\nWeighted Precision Calculation:\")\n",
    "for i, (class_precision, weight_sum) in enumerate(zip(precision, weighted_sums)):\n",
    "    print(f\"  Class {i+1} Precision: {class_precision:.4f}, Weight (Number of instances in class): {confusion_matrix[i, :].sum()}\")\n",
    "print(f\"  Sum of weighted precisions: {np.sum(weighted_sums)}\")\n",
    "print(f\"  Total number of instances: {total_instances}\")\n",
    "print(f\"  Weighted Precision: Sum of Weighted Precisions / Total Instances = {np.sum(weighted_sums)} / {total_instances} = {weighted_precision:.4f}\")\n",
    "\n",
    "# ... [rest of the code] ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b3fcc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
